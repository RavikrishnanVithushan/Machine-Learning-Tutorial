<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>How MLP Depth Affects Performance: A Hands-On Tutorial</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
    content="Tutorial exploring how the depth of a Multilayer Perceptron (MLP) affects performance and overfitting on the Fashion-MNIST dataset.">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"
    integrity="sha512-BNa5s4r1s1z3q...==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js" integrity="sha512-3m6p...=="
    crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <style>
    :root {
      --bg: #0f172a;
      --bg-alt: #111827;
      --card: #020617;
      --accent: #38bdf8;
      --accent-soft: rgba(56, 189, 248, 0.2);
      --text: #e5e7eb;
      --muted: #9ca3af;
      --border: #1f2937;
      --danger: #f97373;
      --code-bg: #020617;
      --heading: #f9fafb;
      --max-width: 900px;
      --radius-lg: 18px;
      --radius-sm: 8px;
      --shadow-soft: 0 18px 45px rgba(15, 23, 42, 0.9);
      --tab-bg: rgba(15, 25, 42, 0.95);
      --nav-bg: linear-gradient(to bottom, rgba(15, 23, 42, 0.96), rgba(15, 23, 42, 0.75), transparent);
      --details-bg: rgba(15, 23, 42, 0.8);
      --inline-math-bg: rgba(15, 23, 42, 0.9);
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: radial-gradient(circle at top, #1e293b 0, #020617 45%, #000 100%);
      color: var(--text);
      line-height: 1.6;
    }

    main {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 2.5rem 1.25rem 3.5rem;
    }

    header {
      text-align: center;
      margin-bottom: 2.5rem;
    }

    .badge {
      display: inline-flex;
      align-items: center;
      gap: 0.4rem;
      font-size: 0.75rem;
      padding: 0.25rem 0.6rem;
      border-radius: 999px;
      background: var(--tab-bg);
      border: 1px solid rgba(148, 163, 184, 0.35);
      color: var(--muted);
    }

    .badge-dot {
      width: 7px;
      height: 7px;
      border-radius: 999px;
      background: var(--accent);
      box-shadow: 0 0 0 4px rgba(56, 189, 248, 0.25);
    }

    h1 {
      font-size: clamp(1.9rem, 4vw, 2.4rem);
      margin: 0.75rem 0;
      color: var(--heading);
      letter-spacing: 0.02em;
    }

    .subtitle {
      color: var(--muted);
      max-width: 620px;
      margin: 0.5rem auto 0;
      font-size: 0.95rem;
    }

    .meta {
      margin-top: 1rem;
      font-size: 0.8rem;
      color: var(--muted);
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 0.8rem;
    }

    .meta span {
      display: inline-flex;
      align-items: center;
      gap: 0.25rem;
    }

    .pill {
      font-size: 0.75rem;
      padding: 0.15rem 0.5rem;
      border-radius: 999px;
      border: 1px solid rgba(148, 163, 184, 0.32);
    }

    .grid {
      display: grid;
      gap: 1.5rem;
    }

    @media (min-width: 900px) {
      .grid-2 {
        grid-template-columns: 1.2fr 0.9fr;
      }
    }

    .card {
      background: radial-gradient(circle at top left, rgba(56, 189, 248, 0.09), transparent 55%),
        radial-gradient(circle at bottom right, rgba(59, 130, 246, 0.2), transparent 55%),
        var(--card);
      border-radius: var(--radius-lg);
      border: 1px solid rgba(148, 163, 184, 0.3);
      box-shadow: var(--shadow-soft);
      padding: 1.35rem 1.3rem;
      position: relative;
      overflow: hidden;
    }

    .card::before {
      content: "";
      position: absolute;
      inset: 0;
      background: radial-gradient(circle at top, rgba(248, 250, 252, 0.06), transparent 52%);
      opacity: 0.7;
      pointer-events: none;
    }

    .card>* {
      position: relative;
      z-index: 1;
    }

    .card h2 {
      font-size: 1.1rem;
      margin-top: 0;
      margin-bottom: 0.4rem;
      color: var(--heading);
    }

    .card h3 {
      font-size: 1rem;
      margin-top: 1.1rem;
      margin-bottom: 0.4rem;
      color: var(--heading);
    }

    .card p {
      font-size: 0.9rem;
      color: var(--text);
    }

    .highlight {
      border-left: 3px solid var(--accent);
      padding-left: 0.7rem;
      margin: 0.8rem 0;
      font-size: 0.9rem;
      color: var(--muted);
    }

    code,
    pre {
      font-family: "JetBrains Mono", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.8rem;
    }

    pre {
      background: var(--code-bg);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border);
      padding: 0.85rem;
      overflow-x: auto;
      margin: 0.7rem 0 1rem;
    }

    pre::-webkit-scrollbar {
      height: 6px;
    }

    pre::-webkit-scrollbar-thumb {
      background: #4b5563;
      border-radius: 999px;
    }

    .kbd {
      font-family: inherit;
      font-size: 0.75rem;
      border-radius: 6px;
      border: 1px solid var(--border);
      padding: 0.08rem 0.35rem;
      background: rgba(15, 23, 42, 0.85);
    }

    a {
      color: var(--accent);
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .tab-bar {
      display: inline-flex;
      border-radius: 999px;
      padding: 0.15rem;
      background: var(--tab-bg);
      border: 1px solid rgba(148, 163, 184, 0.35);
      margin-bottom: 0.5rem;
    }

    .tab-button {
      border: none;
      background: transparent;
      color: var(--muted);
      font-size: 0.8rem;
      padding: 0.2rem 0.75rem;
      border-radius: 999px;
      cursor: pointer;
      transition: background 0.2s, color 0.2s;
    }

    .tab-button[aria-selected="true"] {
      background: var(--accent-soft);
      color: var(--heading);
    }

    .tab-panel {
      display: none;
    }

    .tab-panel.active {
      display: block;
    }

    .badge-small {
      display: inline-flex;
      align-items: center;
      gap: 0.25rem;
      font-size: 0.75rem;
      color: var(--muted);
      margin-bottom: 0.6rem;
    }

    .color-palette {
      display: flex;
      gap: 0.4rem;
      margin-top: 0.3rem;
    }

    .swatch {
      width: 18px;
      height: 18px;
      border-radius: 999px;
      border: 1px solid rgba(15, 23, 42, 0.75);
    }

    .swatch.blue {
      background: #2563eb;
    }

    .swatch.orange {
      background: #f97316;
    }

    .swatch.purple {
      background: #a855f7;
    }

    .section-heading {
      margin: 2rem 0 0.8rem;
      font-size: 1.1rem;
      color: var(--heading);
    }

    ul,
    ol {
      padding-left: 1.25rem;
    }

    li {
      font-size: 0.9rem;
      margin-bottom: 0.25rem;
    }

    .footer {
      margin-top: 2.5rem;
      font-size: 0.8rem;
      color: var(--muted);
      text-align: center;
    }

    .callout {
      margin-top: 0.75rem;
      border-radius: var(--radius-sm);
      border: 1px dashed rgba(148, 163, 184, 0.6);
      padding: 0.7rem 0.8rem;
      background: var(--details-bg);
      font-size: 0.85rem;
    }

    .inline-math {
      font-family: "JetBrains Mono", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.85em;
      background: var(--inline-math-bg);
      padding: 0.08rem 0.28rem;
      border-radius: 4px;
    }

    /* Expandable sections */
    details {
      margin-top: 0.7rem;
      border-radius: var(--radius-sm);
      border: 1px solid rgba(148, 163, 184, 0.4);
      background: var(--details-bg);
      padding: 0.55rem 0.7rem 0.6rem;
    }

    details summary {
      cursor: pointer;
      font-size: 0.9rem;
      color: var(--heading);
      list-style: none;
    }

    details summary::marker,
    details summary::-webkit-details-marker {
      display: none;
    }

    details[open] {
      border-color: var(--accent);
    }

    details p,
    details ul {
      margin-top: 0.4rem;
      font-size: 0.85rem;
    }

    /* Anchor headings for screen readers */
    h2[id],
    h3[id] {
      scroll-margin-top: 80px;
    }

    nav {
      position: sticky;
      top: 0;
      z-index: 50;
      background: var(--nav-bg);
      backdrop-filter: blur(16px);
      margin-bottom: 0.75rem;
    }

    .nav-inner {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 0.4rem 1.25rem 0.7rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      font-size: 0.8rem;
      color: var(--muted);
      gap: 1rem;
    }

    .nav-links {
      display: flex;
      gap: 0.7rem;
      flex-wrap: wrap;
    }

    .nav-links a {
      text-decoration: none;
      color: var(--muted);
      padding: 0.15rem 0.45rem;
      border-radius: 999px;
    }

    .nav-links a:hover {
      background: rgba(15, 23, 42, 0.9);
      color: var(--heading);
    }

    .nav-brand {
      font-weight: 600;
      letter-spacing: 0.04em;
      text-transform: uppercase;
      font-size: 0.75rem;
    }

    .qa-container {
      margin-top: 40px;
      padding: 20px;
    }

    .qa-box {
      border: 1px solid #ccc;
      border-radius: 8px;
      padding: 15px;
      background: var(--card-bg, #f9f9f9);
    }

    #qa-messages {
      height: 250px;
      overflow-y: auto;
      padding: 10px;
      border-bottom: 1px solid #ddd;
      margin-bottom: 10px;
    }

    .message {
      margin-bottom: 12px;
    }

    .message.user {
      text-align: right;
      font-weight: bold;
    }

    .message.ai {
      text-align: left;
      color: #333;
    }

    .qa-input-row {
      display: flex;
      gap: 8px;
    }

    #qa-input {
      flex: 1;
      padding: 10px;
      border-radius: 6px;
      border: 1px solid #aaa;
    }

    #qa-send-btn {
      padding: 10px 18px;
      background: #007bff;
      border: none;
      color: white;
      border-radius: 6px;
      cursor: pointer;
    }

    #qa-send-btn:hover {
      background: #0056b3;
    }


    /* --- Theme variables (dark by default) --- */
    :root {
      --bg: #0f172a;
      --text: #e5e7eb;
      --card: #020617;
      --accent: #38bdf8;
      --muted: #9ca3af;
      --panel-bg: rgba(255, 255, 255, 0.03);
      --tab-bg: rgba(15, 25, 42, 0.95)
    }

    .theme-light {
      --bg: #f3f5f7;
      --text: #0b1220;
      --card: #def2ed;
      --accent: #101315;
      --muted: #11171e;
      --panel-bg: rgba(250, 245, 245, 0.653);
      --tab-bg: rgba(245, 245, 245, 0.95);
      --code-bg: rgba(213, 235, 245, 0.744);
      --heading: #111827;
      --nav-bg: linear-gradient(to bottom, rgba(245, 245, 245, 0.96), rgba(245, 245, 245, 0.75), transparent);
      --details-bg: rgb(230 234 243 / 80%);
      --inline-math-bg: rgb(195 206 234 / 90%);
    }

    .dark {
      background-color: #111;
      color: white;
    }

    .light {
      background-color: white;
      color: black;
    }



    /* apply to body and components that use variables */
    body {
      background: var(--bg);
      color: var(--text);
    }

    .card {
      background: var(--card);
    }

    /* Floating toolbar */
    #float-toolbar {
      position: fixed;
      right: 18px;
      top: 84px;
      display: flex;
      gap: 8px;
      align-items: center;
      background: var(--panel-bg);
      border: 1px solid rgba(148, 163, 184, 0.08);
      padding: 8px;
      border-radius: 12px;
      z-index: 120;
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.45);
    }


    /* toolbar buttons */
    #float-toolbar button,
    #float-toolbar select,
    #float-toolbar input {
      background: transparent;
      border: none;
      color: var(--text);
      padding: 6px 8px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 0.95rem;
    }

    #float-toolbar button:focus,
    #float-toolbar select:focus,
    #float-toolbar input:focus {
      outline: 2px solid var(--accent);
      outline-offset: 2px;
    }

    /* small-screen adjustments */
    @media (max-width: 680px) {
      #float-toolbar {
        right: 10px;
        top: 68px;
        gap: 6px;
        padding: 6px;
      }

      #voice-select {
        display: none;
      }

      /* keep mobile compact */
    }

    /* invisible label for screen-readers */
    .sr-only {
      position: absolute !important;
      height: 1px;
      width: 1px;
      overflow: hidden;
      clip: rect(1px, 1px, 1px, 1px);
      white-space: nowrap;
    }

    /* -----------------------------
   
    /* Place tools on right: nav-inner already spaces items; keep them aligned */
    .nav-tools {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      margin-left: auto;
      /* push to right */
    }

    /* Buttons inside navbar */
    .nav-tool-btn {
      background: transparent;
      border: 1px solid rgba(148, 163, 184, 0.08);
      color: var(--muted);
      padding: 6px 8px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 0.95rem;
      display: inline-flex;
      align-items: center;
      gap: 6px;
    }

    .nav-tool-btn:hover {
      color: var(--heading);
      border-color: rgba(56, 189, 248, 0.14);
      background: rgba(56, 189, 248, 0.03);
    }

    /* Voice select & rate slider */
    .nav-audio {
      display: inline-flex;
      align-items: center;
      gap: 0.4rem;
    }

    /* smaller select styling */
    .nav-tool-select {
      min-width: 160px;
      max-width: 220px;
      background: transparent;
      border: 1px solid rgba(148, 163, 184, 0.08);
      color: var(--text);
      padding: 4px 6px;
      border-radius: 6px;
      font-size: 0.85rem;
    }

    /* range style small */
    .nav-tool-range {
      width: 90px;
      height: 26px;
      background: transparent;
      accent-color: var(--accent);
    }

    /* Responsiveness: hide voice select on narrow screens and reduce spacing */
    @media (max-width: 820px) {
      .nav-tool-select {
        display: none;
      }

      .nav-tool-range {
        width: 70px;
        display: none;
      }

      /* hide slider to keep navbar compact */
      .nav-audio {
        gap: 0.25rem;
      }

      .nav-tools {
        gap: 0.25rem;
      }
    }

    /* Focus outlines for accessibility */
    .nav-tool-btn:focus,
    .nav-tool-select:focus {
      outline: 2px solid var(--accent);
      outline-offset: 2px;
    }
  </style>
</head>

<body>
  <nav aria-label="Tutorial navigation">
    <div class="nav-inner">
      <div class="nav-brand">MLP Depth Tutorial</div>
      <div class="nav-links">
        <a href="#intro">Intro</a>
        <a href="#theory">Theory</a>
        <a href="#experiment">Experiment</a>
        <a href="#results">Results</a>
        <a href="#references">References</a>
      </div>
      <div class="nav-tools" role="region" aria-label="Toolbar">
        <button id="theme-toggle" class="nav-tool-btn" aria-pressed="false" aria-label="Toggle theme">üåó</button>

        <button id="download-pdf" class="nav-tool-btn" aria-label="Download tutorial as PDF">‚¨áÔ∏è</button>

        <div class="nav-audio" aria-label="Audio controls">
          <button id="tts-play" class="nav-tool-btn" aria-label="Play narration">‚ñ∂Ô∏è</button>
          <button id="tts-pause" class="nav-tool-btn" aria-label="Pause narration">‚è∏Ô∏è</button>
          <button id="tts-stop" class="nav-tool-btn" aria-label="Stop narration">‚èπÔ∏è</button>

          <select style='display: none;' id="voice-select" class="nav-tool-select" aria-label="Select voice"
            title="Voice"></select>
          <input style='display: none;' id="rate" class="nav-tool-range" type="range" min="0.6" max="1.8" step="0.1"
            value="1" aria-label="Speech rate" title="Speech rate" />
        </div>
      </div>
    </div>
  </nav>

  <main>
    <header id="intro">
      <div class="badge" aria-label="Tutorial meta information">
        <span class="badge-dot" aria-hidden="true"></span>
        Deep Learning ¬∑ Multilayer Perceptron
      </div>
      <h1>Does Making an MLP Deeper Always Make It Better?</h1>
      <p class="subtitle">
        In this tutorial we explore how the number of hidden layers in a Multilayer Perceptron (MLP)
        changes its performance and overfitting behaviour on the Fashion-MNIST image classification task.
        The goal is to give you enough intuition and code so you can design sensible MLPs in your own work.
      </p>
      <div class="meta">
        <span>‚è± &lt; 10 minute read</span>
        <span>üìä Dataset: Fashion-MNIST (10 classes, 28√ó28 grayscale images)</span>
        <span class="pill">GitHub: <a href="https://github.com/RavikrishnanVithushan/Machine-Learning-Tutorial"
            target="_blank" rel="noopener">repository link</a></span>
      </div>
    </header>

    <section class="grid grid-2">
      <article class="card" aria-labelledby="theory-heading" id="theory">
        <h2 id="theory-heading">1. Intuition: What Is an MLP, and What Does ‚ÄúDepth‚Äù Mean?</h2>
        <p>
          A Multilayer Perceptron (MLP) is a stack of fully connected layers. Each neuron computes a
          weighted sum of its inputs plus a bias, then passes this through a nonlinear activation. For
          a neuron with weights <span class="inline-math">w</span>, input
          <span class="inline-math">x</span> and bias <span class="inline-math">b</span>, we compute
          <span class="inline-math">z = w·µÄx + b</span>, then apply an activation such as ReLU.
        </p>
        <p>
          The network has an <strong>input layer</strong> (our pixels), one or more
          <strong>hidden layers</strong>, and an <strong>output layer</strong> that returns class
          probabilities. When we talk about depth in this tutorial, we specifically mean the
          <em>number of hidden layers</em>.
        </p>

        <div class="highlight" role="note">
          <strong>Key idea:</strong> deeper MLPs can represent more complex functions with fewer neurons,
          but they are also harder to train and more likely to overfit if we are not careful.
        </div>

        <p>
          Training an MLP means finding weights that minimise a loss function (here:
          cross-entropy) using stochastic gradient descent (we will use the Adam optimiser). We
          monitor both <strong>training</strong> and <strong>validation</strong> performance to see
          how well the model generalises beyond the data it directly sees during optimisation.
        </p>

        <h3>Overfitting vs generalisation</h3>
        <p>
          As we increase depth, the model‚Äôs capacity grows. At first this is helpful: the MLP
          captures more of the structure in the data. But past a certain point, the model can start
          to memorise noise instead of learning general patterns. This appears as:
        </p>
        <ul>
          <li>Training accuracy keeps climbing.</li>
          <li>Validation accuracy saturates or gets worse.</li>
          <li>Validation loss may start to increase even while training loss decreases.</li>
        </ul>
        <p>
          Our experiment is designed to visualise exactly this effect.
        </p>
      </article>

      <aside class="card" aria-labelledby="setup-heading">
        <h2 id="setup-heading">2. Experimental Setup at a Glance</h2>

        <h3>Dataset: Fashion-MNIST</h3>
        <p>
          Fashion-MNIST contains 70,000 clothing images (28√ó28 grayscale), split into
          60,000 training and 10,000 test samples. There are 10 classes such as T-shirt/top,
          trouser, pullover and sneaker. Compared to classic digit MNIST, it is slightly more
          challenging but still small enough to train quickly on a CPU.
        </p>

        <h3>What we vary (and keep fixed)</h3>
        <ul>
          <li><strong>Variable:</strong> number of hidden layers (depth) ‚àà {1, 2, 4}.</li>
          <li><strong>Hidden units:</strong> 128 neurons per hidden layer.</li>
          <li><strong>Activation:</strong> ReLU for hidden layers, softmax for output.</li>
          <li><strong>Optimiser:</strong> Adam, learning rate 1e-3.</li>
          <li><strong>Batch size:</strong> 128.</li>
          <li><strong>Epochs:</strong> 20.</li>
          <li><strong>Split:</strong> 50k train / 10k validation / 10k test.</li>
        </ul>

        <details>
          <summary>Why only up to 4 layers?</summary>
          <p>
            The goal is not to build the best possible Fashion-MNIST classifier, but to show how
            behaviour changes with depth while keeping training fast. Very deep fully connected
            networks on small images tend to overfit heavily without additional regularisation.
          </p>
        </details>

        <div class="callout" id="experiment">
          <strong>Reproducibility:</strong> All code used to generate the plots in this tutorial is
          available in the accompanying Jupyter notebook:
          <code>mlp_depth_fashion_mnist.ipynb</code>. You can run it end-to-end to reproduce the
          figures.
        </div>
      </aside>
    </section>

    <section aria-labelledby="code-heading">
      <h2 class="section-heading" id="code-heading">3. Core Code: Building and Training MLPs with Different Depths</h2>

      <p>
        The notebook uses TensorFlow / Keras. Below is a simplified version of the key parts.
        Installation (e.g. <code>pip install tensorflow</code>) is included in the notebook but omitted here
        for brevity.
      </p>

      <div class="badge-small" aria-label="Interactive code tabs">
        <span>üíª Toggle between data prep and model code:</span>
      </div>

      <div class="tab-bar" role="tablist" aria-label="Code sections">
        <button class="tab-button" role="tab" aria-selected="true" aria-controls="tab-data" id="tab-btn-data">
          3.1 Data preparation
        </button>
        <button class="tab-button" role="tab" aria-selected="false" aria-controls="tab-model" id="tab-btn-model">
          3.2 Model &amp; training loop
        </button>
      </div>

      <div id="tab-data" class="tab-panel active" role="tabpanel" aria-labelledby="tab-btn-data">
        <pre aria-label="Python code for loading and preparing Fashion-MNIST"><code># 3.1 Data preparation (in notebook: see first cell)
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Load Fashion-MNIST
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Normalise pixel values to [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test  = x_test.astype("float32") / 255.0

# Flatten 28x28 -> 784 for the MLP
x_train = x_train.reshape(-1, 28 * 28)
x_test  = x_test.reshape(-1, 28 * 28)

# Split train into train + validation
x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train_small = x_train[:-10000]
y_train_small = y_train[:-10000]</code></pre>
      </div>

      <div id="tab-model" class="tab-panel" role="tabpanel" aria-labelledby="tab-btn-model">
        <pre aria-label="Python code for creating and training MLPs with variable depth"><code># 3.2 Creating an MLP with variable depth
def create_mlp(num_hidden_layers=1, hidden_units=128, input_dim=784, num_classes=10):
    model = keras.Sequential()
    model.add(layers.Input(shape=(input_dim,)))

    for _ in range(num_hidden_layers):
        model.add(layers.Dense(hidden_units, activation="relu"))

    model.add(layers.Dense(num_classes, activation="softmax"))

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-3),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

depths = [1, 2, 4]
histories = {}
test_scores = {}

for d in depths:
    print(f"Training MLP with depth = {d} hidden layers")
    model = create_mlp(num_hidden_layers=d)

    history = model.fit(
        x_train_small, y_train_small,
        validation_data=(x_val, y_val),
        epochs=20,
        batch_size=128,
        verbose=2,
    )

    histories[d] = history.history

    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    test_scores[d] = (test_loss, test_acc)
    print(f"Depth {d}, test accuracy = {test_acc:.4f}")</code></pre>
      </div>

      <p>
        The notebook then uses Matplotlib to create two main visual summaries:
      </p>
      <ol>
        <li>Training vs validation accuracy curves for each depth.</li>
        <li>Test accuracy bar chart comparing depths 1, 2 and 4.</li>
      </ol>
    </section>

    <section aria-labelledby="results-heading" id="results">
      <h2 class="section-heading" id="results-heading">4. Results: What Happens as We Make the MLP Deeper?</h2>

      <article class="card">
        <h3>4.1 Accuracy curves over epochs</h3>
        <p>
          The first figure in the notebook shows training and validation accuracy as a function of
          epoch for each depth. In my runs, a consistent pattern emerged:
        </p>
        <ul>
          <li>
            Going from <strong>1 ‚Üí 2 hidden layers</strong> improved both validation and test
            accuracy. The model gained enough capacity to capture more structure in Fashion-MNIST.
          </li>
          <li>
            Going from <strong>2 ‚Üí 4 hidden layers</strong> increased training accuracy further, but
            validation accuracy only improved slightly and sometimes became noisier.
          </li>
        </ul>
        <p>
          This is a classic signal of overfitting: the deepest model is powerful enough to almost
          memorise the training samples, but not all of that extra complexity translates into better
          generalisation.
        </p>

        <h3>4.2 Test accuracy comparison</h3>
        <p>
          The second figure (a simple bar chart) summarises final test accuracy. Exact numbers
          depend on the random seed, but a typical outcome was:
        </p>
        <ul>
          <li>Depth 1: solid baseline performance.</li>
          <li>Depth 2: usually the best test accuracy.</li>
          <li>Depth 4: similar or only slightly better than depth 2, despite higher complexity.</li>
        </ul>

        <div class="highlight">
          <strong>Take-away:</strong> there is a ‚Äúsweet spot‚Äù where the MLP is deep enough to model
          the data but not so deep that it burns capacity on noise. For this simple image task, two
          hidden layers of width 128 strike a good balance.
        </div>
      </article>

      <article class="card">
        <h3>4.3 Practical advice: how to pick depth in your own projects</h3>
        <ul>
          <li>
            <strong>Start shallow:</strong> begin with 1‚Äì2 hidden layers and a reasonable width
            (e.g. 64‚Äì256 units).
          </li>
          <li>
            <strong>Use a validation set:</strong> always monitor validation loss and accuracy, not
            just training metrics.
          </li>
          <li>
            <strong>Increase depth only when needed:</strong> if both training and validation
            performance are poor and underfitting is likely, then consider adding depth or width.
          </li>
          <li>
            <strong>Add regularisation for deeper MLPs:</strong> techniques such as dropout,
            weight decay (L2), and early stopping help control overfitting when you do need deeper
            networks.
          </li>
          <li>
            <strong>For images, consider CNNs:</strong> for more realistic image tasks, convolutional
            neural networks are usually a better architectural choice than very deep fully connected
            MLPs.
          </li>
        </ul>
      </article>
    </section>

    <section aria-labelledby="references-heading" id="references">
      <h2 class="section-heading" id="references-heading">6. References and Further Reading</h2>
      <p>
        The following resources informed this tutorial and are good starting points if you want to
        go deeper into MLPs and model capacity:
      </p>
      <ol>
        <li>
          <a href="https://aikosh.indiaai.gov.in/static/Deep+Learning+Ian+Goodfellow.pdf" target="_blank"
            rel="noopener">
            I. Goodfellow, Y. Bengio, A. Courville,
            <em>Deep Learning</em>, MIT Press, 2016. (Chapters on feedforward networks and capacity /
            regularisation.)
          </a>

        </li>
        <li>
          <a href="https://www.nature.com/articles/nature14539" target="_blank" rel="noopener">
            Y. LeCun, Y. Bengio, G. Hinton,
            ‚ÄúDeep learning,‚Äù <em>Nature</em>, 521, 436‚Äì444, 2015.
          </a>

        </li>
        <li>
          H. Xiao, K. Rasul, R. Vollgraf,
          ‚ÄúFashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms,‚Äù
          2017. Dataset and description at the official <a href="https://github.com/zalandoresearch/fashion-mnist"
            target="
          _blank" rel="noopener">repository.</a>
        </li>
        <li>
          TensorFlow/Keras documentation:
          <a href="https://keras.io/" target="_blank" rel="noopener">https://keras.io/</a>
          ‚Äì for API details on <code>Dense</code> layers, optimisers and training loops.
        </li>
        <li>
          Articles on overfitting and model capacity:
          <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/"
            target="_blank" rel="noopener">
            https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/
          </a>
      </ol>
      <p>
        The GitHub repository for this tutorial (including the notebook, exported figures and this
        webpage) is available at:
        <a href="https://github.com/RavikrishnanVithushan/Machine-Learning-Tutorial" target="_blank"
          rel="noopener">https://github.com/RavikrishnanVithushan/Machine-Learning-Tutorial</a>.
      </p>
    </section>
    <section id="qa-section" class="qa-container">
      <h2>Ask Me Anything (Q&A)</h2>

      <div class="qa-box">
        <div id="qa-messages"></div>

        <div class="qa-input-row">
          <input type="text" id="qa-input" placeholder="Type your question here...">
          <button id="qa-send-btn">Ask</button>
        </div>
      </div>
    </section>


    <footer class="footer">
      <p>
        Built as part of a machine learning coursework to teach how MLP depth affects performance
        and overfitting on a real dataset. Code is provided so that you can rerun and adapt the
        experiment for your own projects.
      </p>
    </footer>
  </main>

  <script>
    // Simple tab switcher for code blocks (accessibility-friendly)
    (function () {
      const tabButtons = document.querySelectorAll(".tab-button");
      const tabPanels = document.querySelectorAll(".tab-panel");

      tabButtons.forEach(btn => {
        btn.addEventListener("click", () => {
          const targetId = btn.getAttribute("aria-controls");

          tabButtons.forEach(b => b.setAttribute("aria-selected", "false"));
          tabPanels.forEach(p => p.classList.remove("active"));

          btn.setAttribute("aria-selected", "true");
          document.getElementById(targetId).classList.add("active");
        });
      });
    })();
  </script>
  <script>
    /* ---------------------------
       THEME TOGGLE (persist via localStorage)
       --------------------------- */
    (function () {
      const root = document.documentElement;
      const body = document.body;
      const toggleBtn = document.getElementById('theme-toggle');
      const STORAGE_KEY = 'mlp_tutorial_theme'; // 'dark' or 'light'

      // apply theme from localStorage or system preference
      function applyTheme(theme) {
        if (theme === 'light') {
          body.classList.add('theme-light');
          toggleBtn.setAttribute('aria-pressed', 'true');

        } else {
          body.classList.remove('theme-light');
          toggleBtn.setAttribute('aria-pressed', 'false');
        }
      }

      const saved = localStorage.getItem(STORAGE_KEY);
      if (saved) {
        applyTheme(saved);
      } else {
        // default: respect prefers-color-scheme
        const prefersLight = window.matchMedia && window.matchMedia('(prefers-color-scheme: light)').matches;
        applyTheme(prefersLight ? 'light' : 'dark');
      }

      toggleBtn.addEventListener('click', () => {
        const isLight = body.classList.toggle('theme-light');
        const newTheme = isLight ? 'light' : 'dark';
        localStorage.setItem(STORAGE_KEY, newTheme);
        applyTheme(newTheme);
      });
    })();

    /* ---------------------------
       PDF EXPORT (html2canvas + jsPDF)
       --------------------------- */
    (async function () {
      const btn = document.getElementById('download-pdf');
      if (!btn) return;
      btn.addEventListener('click', async () => {
        btn.disabled = true;
        btn.textContent = '‚è≥ Preparing PDF...';

        try {
          // target the main content; adjust selector if needed
          const element = document.querySelector('main') || document.body;
          // increase scale for better resolution
          const scale = 2;
          const canvas = await html2canvas(element, {
            backgroundColor: getComputedStyle(document.body).getPropertyValue('--bg') || null,
            scale: scale,
            useCORS: true,
            logging: false
          });

          // use jsPDF
          const { jsPDF } = window.jspdf;
          const pdf = new jsPDF('p', 'pt', 'a4');
          const imgData = canvas.toDataURL('image/png');

          // Calculate width/height to fit A4
          const pdfWidth = pdf.internal.pageSize.getWidth();
          const pdfHeight = (canvas.height * pdfWidth) / canvas.width;

          pdf.addImage(imgData, 'PNG', 0, 0, pdfWidth, pdfHeight);
          // if content longer than one page, add more pages
          if (pdfHeight > pdf.internal.pageSize.getHeight()) {
            let heightLeft = pdfHeight;
            let position = 0;
            while (heightLeft > 0) {
              position = heightLeft - pdf.internal.pageSize.getHeight();
              if (position <= 0) break;
              pdf.addPage();
              pdf.addImage(imgData, 'PNG', 0, -position, pdfWidth, pdfHeight);
              heightLeft -= pdf.internal.pageSize.getHeight();
            }
          }

          // filename with date
          const now = new Date();
          const filename = `mlp-depth-tutorial-${now.toISOString().slice(0, 10)}.pdf`;
          pdf.save(filename);
        } catch (err) {
          console.error('PDF generation failed', err);
          alert('Could not create PDF in this browser. Try using Chrome or Firefox.');
        } finally {
          btn.disabled = false;
          btn.textContent = '‚¨áÔ∏è Download PDF';
        }
      });
    })();

    /* ---------------------------
       TEXT-TO-SPEECH (Web Speech API)
       --------------------------- */
    (function () {
      if (!('speechSynthesis' in window)) {
        // disable audio controls if not supported
        const audioWrapper = document.querySelector('.nav-audio');
        if (audioWrapper) audioWrapper.innerHTML = '<em style="color:var(--muted)">Audio not supported</em>';
        return;
      }

      const synth = window.speechSynthesis;
      const playBtn = document.getElementById('tts-play');
      const pauseBtn = document.getElementById('tts-pause');
      const stopBtn = document.getElementById('tts-stop');
      const voiceSelect = document.getElementById('voice-select');
      const rateInput = document.getElementById('rate');

      let utter = null;
      let voices = [];

      function populateVoices() {
        voices = synth.getVoices().filter(v => v.lang && v.name);
        // optional sort prefer english
        voices.sort((a, b) => (a.lang === 'en-US' ? -1 : 0));
        if (!voiceSelect) return;
        voiceSelect.innerHTML = '';
        voices.forEach((v, i) => {
          const opt = document.createElement('option');
          opt.value = i;
          opt.textContent = `${v.name} ‚Äî ${v.lang}`;
          voiceSelect.appendChild(opt);
        });
        // hide select on very small screens handled by CSS
      }

      populateVoices();
      if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = populateVoices;
      }

      function buildText() {
        const main = document.querySelector('main') || document.body;
        const clone = main.cloneNode(true);
        // remove elements not helpful for TTS
        const elemsToRemove = clone.querySelectorAll('nav, footer, .tab-bar, pre, code, [aria-hidden="true"]');
        elemsToRemove.forEach(e => e.remove());
        return clone.innerText;
      }

      function createUtterance() {
        const text = buildText();
        const u = new SpeechSynthesisUtterance(text);
        const selected = voiceSelect && voiceSelect.value ? voices[parseInt(voiceSelect.value)] : voices[0];
        if (selected) u.voice = selected;
        u.rate = parseFloat(rateInput ? rateInput.value : 1) || 1;
        u.onend = () => {
          // re-enable play if needed
          if (playBtn) playBtn.disabled = false;
        };
        u.onerror = (e) => console.error('Speech error', e);
        return u;
      }

      playBtn.addEventListener('click', () => {
        if (!playBtn) return;
        // if paused, resume
        if (synth.paused) {
          synth.resume();
          return;
        }
        // if already speaking, do nothing
        if (synth.speaking) return;
        utter = createUtterance();
        synth.speak(utter);
        playBtn.disabled = false;
      });

      pauseBtn.addEventListener('click', () => {
        if (synth.speaking && !synth.paused) synth.pause();
      });

      stopBtn.addEventListener('click', () => {
        if (synth.speaking || synth.paused) {
          synth.cancel();
          if (playBtn) playBtn.disabled = false;
        }
      });

      // rate change will be applied next time a new utterance is created
    })();
  </script>

  <script src="config.js"></script>

  <script>
    const sendButton = document.getElementById("qa-send-btn");
    const inputField = document.getElementById("qa-input");
    const messagesBox = document.getElementById("qa-messages");

    async function sendQuestion() {
      const question = inputField.value.trim();
      if (!question) return;

      // Display user message
      messagesBox.innerHTML += `<div class="message user">You: ${question}</div>`;
      messagesBox.scrollTop = messagesBox.scrollHeight;
      inputField.value = "";

      // Call OpenAI API
      fetch("/config", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ question: question })
      })
        .then(res => res.json())
        .then(data => {
          console.log(data);
        });

      const answer = data.choices[0].message.content;


      // Display AI message
      messagesBox.innerHTML += `<div class="message ai">AI: ${answer}</div>`;
      messagesBox.scrollTop = messagesBox.scrollHeight;
    }

    sendButton.addEventListener("click", sendQuestion);
    inputField.addEventListener("keypress", (e) => {
      if (e.key === "Enter") sendQuestion();
    });
  </script>


</body>

</html>